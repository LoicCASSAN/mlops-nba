{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model import train_and_save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A executer une fois au début\n",
    "loaded_files = {}\n",
    "players_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on file: C:\\Users\\loicc\\OneDrive - Efrei\\Bureau\\COURS\\M2\\S9\\Machine Learning in Production\\Data Pipeline\\mlops-nba\\2023-2024 NBA Player Stats - Regular.csv\n"
     ]
    }
   ],
   "source": [
    "RAW_DATA_DIR = Path('C:\\\\Users\\\\loicc\\\\OneDrive - Efrei\\\\Bureau\\\\COURS\\\\M2\\\\S9\\\\Machine Learning in Production\\\\Data Pipeline\\\\mlops-nba')\n",
    "\n",
    "# Replace 'nom_du_fichier.csv' with the name of your CSV file\n",
    "filename = RAW_DATA_DIR / '2023-2024 NBA Player Stats - Regular.csv'\n",
    "print(f\"Running on file: {filename}\")\n",
    "players_df = pd.read_csv(filename, sep=',', encoding='Windows-1252')\n",
    "\n",
    "# Add a new 'file' column to the DataFrame\n",
    "players_df['filename'] = filename.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataframe_as_parquet(dataframe, path, filename, file_count=None):\n",
    "    if file_count > 0:\n",
    "        # Modifier le nom du fichier pour inclure le nombre de fichiers traités\n",
    "        modified_filename = filename.replace('.parquet', f'_{file_count}.parquet')\n",
    "    else:\n",
    "        # Garder le nom de fichier original si aucun fichier n'a été traité\n",
    "        modified_filename = filename\n",
    "\n",
    "    # Chemin complet du fichier\n",
    "    full_path = os.path.join(path, modified_filename)\n",
    "\n",
    "    # Sauvegarder le DataFrame en fichier Parquet\n",
    "    dataframe.to_parquet(full_path, index=False)\n",
    "    print(f\"DataFrame sauvegardé en tant que fichier Parquet : {full_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame sauvegardé en tant que fichier Parquet : C:\\Users\\loicc\\OneDrive - Efrei\\Bureau\\COURS\\M2\\S9\\Machine Learning in Production\\Data Pipeline\\mlops-nba\\stockage\\players_raw_1.parquet\n"
     ]
    }
   ],
   "source": [
    "save_dataframe_as_parquet(players_df, 'C:\\\\Users\\\\loicc\\\\OneDrive - Efrei\\\\Bureau\\\\COURS\\\\M2\\\\S9\\\\Machine Learning in Production\\\\Data Pipeline\\\\mlops-nba\\\\stockage', 'players_raw.parquet',1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_players_data(players):\n",
    "    # Assurer que le DataFrame n'est pas vide\n",
    "    if players.empty:\n",
    "        raise ValueError(\"Le DataFrame 'players' est vide.\")\n",
    "\n",
    "    # Ajouter la colonne EFF\n",
    "    players[\"EFF\"] = players.PTS + players.TRB + players.AST + players.STL + players.BLK - \\\n",
    "                     (players.FGA - players.FG) - (players.FTA - players.FT) - players.TOV\n",
    "\n",
    "    # Calculer les statistiques d'âge et de points\n",
    "    ages = players.Age.describe().round(decimals=1)\n",
    "    points = players.PTS.describe().round(decimals=1)\n",
    "\n",
    "    # Définir les critères pour les futurs superstars\n",
    "    young_age = ages[\"25%\"]\n",
    "    futur_super_star_def = f\"(EFF >= 12) & (PTS >= 15) & (Age <= {young_age})\"\n",
    "    players.query(futur_super_star_def).sort_values(\"EFF\", ascending=False).sort_values([\"Age\", \"EFF\"], ascending=True)\n",
    "\n",
    "    # Calculer le pourcentage de tir\n",
    "    players['TS%'] = np.where((2 * (players['FGA'] + 0.44 * players['FTA'])) != 0, \n",
    "                              players['PTS'] / (2 * (players['FGA'] + 0.44 * players['FTA'])), 0)\n",
    "\n",
    "    players[\"Pos\"] = players[\"Pos\"].replace(\"C-PF\", \"C\")\n",
    "    # Mapper les positions des joueurs\n",
    "    players[\"position\"] = players.Pos.map({\"PG\": \"Backcourt\", \"SG\": \"Backcourt\", \n",
    "                                           \"SF\": \"Wing\", \"SF-PF\": \"Wing\", \n",
    "                                           \"PF\": \"Big\", \"C\": \"Big\"})\n",
    "\n",
    "\n",
    "    # Retourner le DataFrame traité\n",
    "    return players\n",
    "\n",
    "# Utilisation de la fonction\n",
    "# players = pd.read_csv('chemin_du_fichier.csv', sep=',', encoding='Windows-1252')\n",
    "# players_processed = process_players_data(players)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "players_df = process_players_data(players_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_and_save_model(players_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame sauvegardé en tant que fichier Parquet : C:\\Users\\loicc\\OneDrive - Efrei\\Bureau\\COURS\\M2\\S9\\Machine Learning in Production\\Data Pipeline\\mlops-nba\\stockage\\players_final_1.parquet\n"
     ]
    }
   ],
   "source": [
    "save_dataframe_as_parquet(players_df, 'C:\\\\Users\\\\loicc\\\\OneDrive - Efrei\\\\Bureau\\\\COURS\\\\M2\\\\S9\\\\Machine Learning in Production\\\\Data Pipeline\\\\mlops-nba\\\\stockage', 'players_final.parquet',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Append DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "# Assurez-vous d'avoir importé les fonctions nécessaires : save_dataframe_as_parquet et train_and_save_model\n",
    "\n",
    "def process_and_train(loaded_files, players_df):\n",
    "    RAW_DATA_DIR = Path('C:\\\\Users\\\\loicc\\\\OneDrive - Efrei\\\\Bureau\\\\COURS\\\\M2\\\\S9\\\\Machine Learning in Production\\\\Data Pipeline\\\\mlops-nba\\\\Append Data')\n",
    "\n",
    "    # Parcourir tous les fichiers CSV dans le dossier\n",
    "    for file_path in RAW_DATA_DIR.glob('*.csv'):\n",
    "        file_name = file_path.name\n",
    "\n",
    "        # Vérifier si le fichier a déjà été lu\n",
    "        if file_name not in loaded_files:\n",
    "            # Lire les données du fichier CSV\n",
    "            new_data = pd.read_csv(file_path, sep=';', encoding='Windows-1252')\n",
    "            new_data['filename'] = file_name\n",
    "\n",
    "            # Sauvegarder la taille actuelle du DataFrame\n",
    "            current_length = len(players_df)\n",
    "\n",
    "            # Concaténer avec le DataFrame principal\n",
    "            players_df = pd.concat([players_df, new_data], ignore_index=True)\n",
    "\n",
    "            # Calculer le nombre de lignes ajoutées\n",
    "            new_lines_added = len(players_df) - current_length\n",
    "            if new_lines_added > 0:\n",
    "                print(f\"{new_lines_added} nouvelles lignes ajoutées depuis {file_name}.\")\n",
    "\n",
    "            # Marquer le fichier comme lu\n",
    "            loaded_files[file_name] = True\n",
    "\n",
    "    # Sauvegarder le DataFrame en tant que fichier Parquet\n",
    "    save_dataframe_as_parquet(players_df, 'C:\\\\Users\\\\loicc\\\\OneDrive - Efrei\\\\Bureau\\\\COURS\\\\M2\\\\S9\\\\Machine Learning in Production\\\\Data Pipeline\\\\mlops-nba\\\\stockage', 'players_append.parquet', len(loaded_files))\n",
    "\n",
    "    \n",
    "    # Entraîner et sauvegarder le modèle\n",
    "    train_and_save_model(players_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame sauvegardé en tant que fichier Parquet : C:\\Users\\loicc\\OneDrive - Efrei\\Bureau\\COURS\\M2\\S9\\Machine Learning in Production\\Data Pipeline\\mlops-nba\\stockage\\players_append_2.parquet\n",
      "RMSE for PTS prediction: 0.8613792533964467\n",
      "RMSE for FG% prediction: 0.05999368458429603\n",
      "Modèle sauvegardé sous : C:\\Users\\loicc\\OneDrive - Efrei\\Bureau\\COURS\\M2\\S9\\Machine Learning in Production\\Data Pipeline\\mlops-nba\\Model\\model_3.joblib\n"
     ]
    }
   ],
   "source": [
    "process_and_train(loaded_files, players_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
